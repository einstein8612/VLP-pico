{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9bdaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90376aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeInput(nn.Module):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x / (x.norm(dim=1, keepdim=True) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bbdcb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            NormalizeInput(),\n",
    "\n",
    "            nn.Linear(36, 64),\n",
    "            nn.ReLU6(),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "\n",
    "            nn.Linear(32, 2),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "116ecd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./MLP-ONLINE-PICO-1749415744.pth\", \"rb\") as f:\n",
    "    model.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61e77fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 00:22:39.897564: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749421359.966873   36997 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749421359.980938   36997 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749421360.088846   36997 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749421360.088974   36997 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749421360.088977   36997 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749421360.088978   36997 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-09 00:22:40.106097: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/root/Github/VLP-pico/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/root/Github/VLP-pico/.venv/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1749421364.117663   36997 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4699 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2025-06-09 00:22:45.480316: W external/local_xla/xla/service/gpu/llvm_gpu_backend/default/nvptx_libdevice_path.cc:40] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  ipykernel_launcher.runfiles/cuda_nvcc\n",
      "  ipykern/cuda_nvcc\n",
      "  \n",
      "  /usr/local/cuda\n",
      "  /opt/cuda\n",
      "  /root/Github/VLP-pico/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /root/Github/VLP-pico/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  /root/Github/VLP-pico/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../cuda\n",
      "  /root/Github/VLP-pico/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../../../../..\n",
      "  /root/Github/VLP-pico/.venv/lib/python3.12/site-packages/tensorflow/python/platform/../../../../../../..\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2025-06-09 00:22:45.567782: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-06-09 00:22:45.579068: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-06-09 00:22:45.579767: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-06-09 00:22:45.581022: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-06-09 00:22:45.583059: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-06-09 00:22:45.585138: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-06-09 00:22:45.593024: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-06-09 00:22:45.611392: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-06-09 00:22:45.614003: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-06-09 00:22:45.618642: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-06-09 00:22:45.620524: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-06-09 00:22:45.622566: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-06-09 00:22:45.624933: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:187] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_tf = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation=tf.nn.relu6, name='linear1', input_shape=(36,)),\n",
    "    tf.keras.layers.Dense(32, name='linear2'),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Dense(2, name='linear3'),\n",
    "])\n",
    "\n",
    "# Triggers layer builds\n",
    "with tf.device('/CPU:0'):\n",
    "    model_tf(tf.zeros((1, 36)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca9768ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "state_dict = torch.load(\"MLP-ONLINE-PICO-1749415744.pth\", map_location=\"cpu\")\n",
    "\n",
    "layer_names = ['linear1', 'linear2', 'linear3']\n",
    "pt_layer_keys = ['1', '3', '5']\n",
    "\n",
    "for tf_name, pt_idx in zip(layer_names, pt_layer_keys):\n",
    "    W = state_dict[f'{pt_idx}.weight'].numpy().T  # [in, out] for TF\n",
    "    b = state_dict[f'{pt_idx}.bias'].numpy()\n",
    "    model_tf.get_layer(tf_name).set_weights([W, b])\n",
    "\n",
    "model_tf.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "280d3579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch output: [[1480.7955 1873.3892]]\n",
      "TensorFlow output: tf.Tensor([[1480.7955 1873.3893]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test if they are equivalent\n",
    "x = np.random.rand(1, 36).astype(np.float32)\n",
    "x = x / (np.linalg.norm(x, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "pt_output = model(torch.tensor(x)).detach().numpy()\n",
    "with tf.device('/CPU:0'):\n",
    "    tf_output = model_tf(x)\n",
    "\n",
    "print(\"PyTorch output:\", pt_output)\n",
    "print(\"TensorFlow output:\", tf_output)\n",
    "\n",
    "# assert np.allclose(pt_output, tf_output, atol=1e-6), \"Outputs are not close enough!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c0fb9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        data = tf.random.uniform(shape=(1, 36), dtype=tf.float32)\n",
    "        yield [data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "020346a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptw3cy93v/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptw3cy93v/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmptw3cy93v'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 36), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140037757143760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140037757144912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140037757143568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140037757142416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140037757145488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140037757142608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Github/VLP-pico/.venv/lib/python3.12/site-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1749421367.156449   36997 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1749421367.156491   36997 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-06-09 00:22:47.157244: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmptw3cy93v\n",
      "2025-06-09 00:22:47.162733: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-06-09 00:22:47.162751: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmptw3cy93v\n",
      "I0000 00:00:1749421367.178296   36997 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "2025-06-09 00:22:47.178994: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-06-09 00:22:47.220788: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmptw3cy93v\n",
      "2025-06-09 00:22:47.228907: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 71666 microseconds.\n",
      "2025-06-09 00:22:47.243218: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_tf)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "# Ensure full integer quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save\n",
    "with open(\"model_int8.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
